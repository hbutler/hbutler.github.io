---
layout: post
title:  "Questioning Parsimony"
date:   2024-12-12 17:00:00 -0700
categories: history
---

[I'm not the first](https://statmodeling.stat.columbia.edu/?s=parsimony&submit=Search) 
to rail against the hand-wavy use of parsimony in statistics (often referred to as 
Occam's Razor). The idea is that the best explanation is the simplest one. In statistics,
we enforce simplicity with penalization of "unnecessary" parameters. I don't know 
when parsimony first became a non-negotiable part of model selection. We can look at the history
of model selection measures that penalize complexity though.

Adjusted R-squared - Mordecai Ezekial 1930
Ridge Regression - Hoerl & Kennard 1970
AIC - Hirotugu Akaike 1971 
BIC - Gideon E. Schwarz 1978
LASSO - Robert Tibsherani 1996

On a seemingly different train of thought, statistics was historically used to justify 
eugenic policies. Much of the statistical methodology that we use today is unchanged from 
the forms it took in the 19th and 20th centuries. 

Has anyone has yet considered any connection between parsimony and eugenics 
and their combined influence on the field of statistics in the 19th and 20th centuries?